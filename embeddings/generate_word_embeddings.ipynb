{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext.util\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from gensim.models.fasttext import FastText \n",
    "from gensim.models import LsiModel\n",
    "import random\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.random_projection import sparse_random_matrix\n",
    "from time import process_time\n",
    "import errno,pickle\n",
    "import numpy as np\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextToTensor:\n",
    "\n",
    "    # --------------------------------------- Constructor --------------------------------------- \n",
    "    \n",
    "    def __init__(self, tokenizer, max_len):\n",
    "    \n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    \n",
    "    def string_to_tensor(self, string_list: list) -> list:\n",
    "        \"\"\"\n",
    "        A method to convert a string list to a tensor for a deep learning model\n",
    "        \"\"\"    \n",
    "        string_list = self.tokenizer.texts_to_sequences(string_list)\n",
    "        string_list = pad_sequences(string_list, maxlen=self.max_len)\n",
    "        \n",
    "        return string_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings:\n",
    "\n",
    "    \"\"\"\n",
    "    A class to read the word embedding file and to create the word embedding matrix\n",
    "    \"\"\"\n",
    "\n",
    "#     def __init__(self, path, vector_dimension):\n",
    "#         self.path = path \n",
    "#         self.vector_dimension = vector_dimension\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_coefs(word, *arr): \n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "    \n",
    "    def get_embedding_index(self):\n",
    "        embeddings_index = dict(self.get_coefs(*o.split(\" \")) for o in open(self.path, errors='ignore'))\n",
    "        return embeddings_index\n",
    "\n",
    "    \n",
    "    def create_embedding_matrix(self, tokenizer, max_features):\n",
    "        \"\"\"\n",
    "        A method to create the embedding matrix\n",
    "        \"\"\"\n",
    "        model_embed = self.get_embedding_index()\n",
    "\n",
    "        embedding_matrix = np.zeros((max_features + 1, self.vector_dimension))\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index > max_features:\n",
    "                break\n",
    "            else:\n",
    "                try:\n",
    "                    embedding_matrix[index] = model_embed[word]\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        return embedding_matrix\n",
    "    \n",
    "    def save_embeddings(self,model,filepath):\n",
    "        \n",
    "        if (\".vec\" in filepath or \".txt\" in filepath):\n",
    "            file = open(filepath, \"w\",encoding= 'utf-8')\n",
    "            words = model.keys()\n",
    "            cnt = 0\n",
    "            for w in words:\n",
    "                v = model[w]\n",
    "                vstr = \"\"\n",
    "                for value in v:\n",
    "                    vstr += \" \" + str(value)\n",
    "                try:\n",
    "                    row = w + vstr + \"\\n\"\n",
    "                    file.write(row)\n",
    "                    cnt += 1\n",
    "                except Exception as e:\n",
    "                    print('Exception: ',e)\n",
    "#                     if e.errno == errno.EPIPE:\n",
    "#                         pass\n",
    "            print('Words processed: ',cnt)\n",
    "\n",
    "        \n",
    "        elif \".plk\" in filepath:\n",
    "            with open(filepath,'wb') as file:\n",
    "                pickle.dump(embeddings_dict, file, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        else:\n",
    "            print('Invalid File type')\n",
    "    \n",
    "    def load_embeddings(self,filepath):\n",
    "        \n",
    "        if (\".vec\" in filepath or \".txt\" in filepath):\n",
    "            print(\"Loading Model\")\n",
    "            f = open(filepath,'r',encoding='utf8')\n",
    "            model = {}\n",
    "\n",
    "            for line in f:\n",
    "                splitLines = line.split()\n",
    "                word = splitLines[0]\n",
    "                wordEmbedding = np.array([float(value) for value in splitLines[1:]])\n",
    "                model[word] = wordEmbedding\n",
    "            print(len(model),\" words loaded.\")\n",
    "\n",
    "            return model\n",
    "        \n",
    "        elif('.plk' in filepath):\n",
    "            print(\"Loading Model\")\n",
    "            f = open(filepathp,'rb',encoding='utf8')\n",
    "            model = pickle.load(f)\n",
    "            print(len(model.keys()),\" words loaded.\")\n",
    "            \n",
    "            return model\n",
    "        \n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def concatenate_embeddings(self,embedding_dict1, embedding_dict2, intersection_only = True):\n",
    "        \n",
    "        embedding_num1 = len(random.choice(list(embedding_dict1.values())))\n",
    "        embedding_num2 = len(random.choice(list(embedding_dict2.values()))) \n",
    "        word_set1 = set(embedding_dict1.keys())\n",
    "        word_set2 = set(embedding_dict2.keys())\n",
    "        print(\"Input Details: \\nSet1: ({},{})\\nSet2: ({},{})\".format(len(word_set1),embedding_num1, len(word_set2),embedding_num2))\n",
    "        concatenated_matrix = np.empty([0,embedding_num1 + embedding_num2])\n",
    "\n",
    "#         count = 0\n",
    "        \n",
    "        if(intersection_only == True):\n",
    "            vocab = word_set1.intersection(word_set2)\n",
    "            print('Common Vocab:',len(vocab))\n",
    "            \n",
    "            for word in vocab:\n",
    "                #print('Accessing word:',word)\n",
    "                vec1 = embedding_dict1[word]\n",
    "                vec2 = embedding_dict2[word]\n",
    "                vec_conc = np.concatenate((vec1,vec2))\n",
    "\n",
    "                concatenated_matrix = np.vstack((concatenated_matrix,vec_conc))\n",
    "#                 count += 1\n",
    "#                 if(count == 10): break\n",
    "                    \n",
    "            print('\\nOutput Shape: ',(concatenated_matrix.shape))\n",
    "        \n",
    "        else:\n",
    "            vocab = word_set1.union(word_set2)\n",
    "            common_v = word_set1.intersection(word_set2)\n",
    "            \n",
    "            for word in vocab:\n",
    "                \n",
    "                if not word in common_v:\n",
    "                    # Logic for projecting embeddings \n",
    "                    vec_conc = np.zeros([0,embedding_num1 + embedding_num2])\n",
    "                    concatenated_matrix = np.vstack((concatenated_matrix,vec_conc))\n",
    "                \n",
    "                else:\n",
    "                    vec1 = embedding_dict1['word']\n",
    "                    vec2 = embedding_dict2['word']\n",
    "                    vec_conc = np.concatenate((vec1,vec2))\n",
    "                    concatenated_matrix = np.vstack((concatenated_matrix,vec_conc))\n",
    "                    \n",
    "        return concatenated_matrix, list(vocab)\n",
    "    \n",
    "    \n",
    "    def perform_SVD(self,matrix, num_components = 2):\n",
    "        \n",
    "            print('Input Shape: {}\\n'.format(matrix.shape))\n",
    "            \n",
    "            svd = TruncatedSVD(n_components = num_components)\n",
    "            new_matrix = svd.fit_transform(matrix)\n",
    "            \n",
    "            print('Output Shape: {}\\n'.format(new_matrix.shape))\n",
    "            \n",
    "            return new_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = Embeddings()\n",
    "# dict1 = {'word1': [1] ,'word2' :[2] ,'word3' :[3]}\n",
    "# dict2 = {'word1': [1] ,'word2' :[2] ,'word4' :[3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model\n",
      "258414  words loaded.\n",
      "Loading Model\n",
      "51954  words loaded.\n"
     ]
    }
   ],
   "source": [
    "indicnlp_embeddings_300 = embed.load_embeddings('../Technodifacation/Embeddings/indicnlp.ft.mr.300.vec')\n",
    "ft_embeddings_300 = embed.load_embeddings('../Technodifacation/models/DS_fasttext_skipgram_cleaned_300.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Details: \n",
      "Set1: (51954,300)\n",
      "Set2: (258414,300)\n",
      "Common Vocab: 29252\n",
      "\n",
      "Output Shape:  (29252, 600)\n",
      "Total time taken:  1609.703125\n"
     ]
    }
   ],
   "source": [
    "start = process_time()\n",
    "concatenation_matrix, vocab_list = embed.concatenate_embeddings(ft_embeddings_300,indicnlp_embeddings_300)\n",
    "end = process_time()\n",
    "print(\"Total time taken: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.32528950e-01, -1.65739860e-01,  5.56280600e-01, -3.37442000e-01,\n",
       "       -4.51513500e-02,  1.17013790e-01, -2.34878110e-01, -6.37767900e-02,\n",
       "       -1.60344100e-01, -3.24652080e-01,  5.03753300e-01,  1.54610350e-02,\n",
       "       -1.27253920e-01,  5.08804860e-01, -1.34303140e-01,  1.40366990e-01,\n",
       "        3.53206220e-01, -3.72080800e-01,  2.22945630e-01, -8.42555500e-01,\n",
       "       -9.86273600e-02, -2.30949060e-01,  6.77504060e-01, -2.67454830e-01,\n",
       "        2.27807800e-02,  1.85186340e-02, -2.08578970e-01,  1.84468730e-01,\n",
       "       -4.04474380e-01,  1.14497580e-01,  3.78842200e-01, -2.10898160e-01,\n",
       "        4.28036180e-01, -1.51156830e-02,  2.64869900e-03, -1.37737150e-01,\n",
       "       -4.26138380e-02,  4.46910140e-01, -3.89181440e-01,  4.50543000e-01,\n",
       "        1.26009350e-01,  8.41780840e-01, -4.10878960e-02, -2.87822430e-01,\n",
       "        8.42054560e-02,  2.38345830e-01, -1.14306370e-01,  2.48483580e-01,\n",
       "       -2.56841200e-01,  2.49823450e-01, -3.76220520e-01,  1.07442334e-01,\n",
       "       -3.05283960e-02, -6.42618500e-01,  8.98350200e-02, -1.76151960e-01,\n",
       "        4.33246460e-01, -1.83382530e-01,  4.62761760e-01,  2.35819060e-01,\n",
       "        4.38969100e-01,  1.94420070e-02,  2.11088180e-01, -8.15420900e-01,\n",
       "        8.35710170e-01,  2.92344360e-01, -2.78227700e-01,  1.78656280e-02,\n",
       "       -2.14083850e-01,  3.12712970e-02, -1.69791970e-01,  7.84864400e-02,\n",
       "       -4.46876670e-01,  3.99822500e-01,  8.94868100e-03,  3.06019840e-01,\n",
       "       -1.01900060e-01,  2.88142900e-01,  1.55598480e-01, -8.08913700e-02,\n",
       "       -1.27981410e-01, -2.75649520e-01, -3.70702330e-01,  1.47988720e-01,\n",
       "       -1.09750210e-01,  6.15247300e-01, -1.25759870e-01, -2.70073830e-01,\n",
       "        2.01376230e-01, -2.44742110e-01, -4.34639400e-02,  6.50545300e-01,\n",
       "        7.02271460e-02, -1.52611170e-01,  4.15010300e-01, -1.05692150e+00,\n",
       "       -7.36570300e-02, -1.62266570e-01,  2.05792530e-01, -7.79871600e-02,\n",
       "        2.80279400e-01,  1.66346300e-01,  7.88282200e-02,  1.87727800e-01,\n",
       "       -9.49851900e-02, -4.25781220e-01,  4.49025420e-01,  5.79661200e-01,\n",
       "        6.63757300e-01,  2.50842460e-02,  2.59600220e-01, -2.88506150e-01,\n",
       "       -4.24339530e-01, -8.54310700e-02, -1.78550850e-01,  1.54114510e-01,\n",
       "       -2.91773140e-02, -3.84832350e-01, -2.77357760e-01, -1.41185940e-01,\n",
       "       -3.50923200e-01,  4.21537460e-01, -2.86167380e-01, -8.68004600e-02,\n",
       "        1.19584575e-01, -2.28381420e-02,  7.77831700e-02,  1.61751100e-01,\n",
       "       -7.84546200e-02, -3.14521300e-01,  1.32751940e-01,  3.46348770e-02,\n",
       "        3.01093460e-01, -3.17716960e-01, -4.66119470e-01,  1.24837190e-01,\n",
       "        2.13632050e-01, -7.21577850e-02,  1.92640000e-01,  3.23344080e-01,\n",
       "       -5.53349800e-01,  7.95128300e-02, -3.68134020e-01, -3.37709580e-01,\n",
       "       -2.82835630e-01,  1.88668620e-01, -3.29726370e-01,  3.71525320e-01,\n",
       "       -2.08192480e-01, -3.73423100e-01,  3.58820600e-01, -2.60611620e-01,\n",
       "       -2.26557450e-01,  5.32132100e-01, -3.34667680e-01, -3.85700500e-01,\n",
       "       -5.50466600e-01, -2.86439210e-02,  5.19541860e-01, -4.34809030e-01,\n",
       "       -6.19204700e-02,  2.02636270e-01, -3.05907460e-01, -3.71371190e-03,\n",
       "        3.79828360e-01, -1.56950370e-01,  1.36041455e-02, -2.53400020e-02,\n",
       "        1.14367090e+00,  4.22515570e-01, -1.24674370e-01,  1.16205760e-02,\n",
       "       -7.96094500e-02,  2.44711120e-01,  5.60761600e-02,  1.78384960e-01,\n",
       "       -1.20173395e-01,  2.62826650e-01, -4.61123260e-01, -4.74997340e-01,\n",
       "        1.95635570e-01, -7.06084300e-01, -3.26051900e-01, -1.79008840e-01,\n",
       "        1.65902180e-01,  2.54745840e-01,  1.84972400e-01, -1.72637600e-01,\n",
       "       -2.00238280e-02,  3.62301230e-01,  1.26628890e-01,  5.12727630e-03,\n",
       "        5.49055300e-03, -3.03820600e-01,  5.18454000e-01,  2.42888600e-01,\n",
       "        6.21823100e-02, -9.59671800e-03, -3.70815430e-02,  6.37852200e-02,\n",
       "        3.48076300e-01,  2.23041140e-02, -3.71314730e-01, -7.55930200e-01,\n",
       "        8.95385700e-02, -4.99247700e-02, -4.61772830e-01, -5.46838100e-01,\n",
       "       -1.05877936e-01, -4.05630140e-01,  1.53052340e-01, -3.47650860e-01,\n",
       "        4.55762920e-01, -6.36415700e-02,  7.71413400e-03, -6.07635200e-01,\n",
       "       -5.71852500e-01, -8.64783760e-01,  5.65800400e-01, -3.69239840e-01,\n",
       "        1.64779930e-01,  2.41696050e-02, -5.21579740e-01, -1.29093800e-01,\n",
       "        5.50760600e-01, -3.05096480e-01,  1.59417200e-01,  3.16336570e-01,\n",
       "       -1.90920070e-01,  9.96881950e-02, -2.95762060e-01, -2.72062930e-01,\n",
       "       -8.32080840e-02,  2.86459180e-01, -1.82073360e-02,  3.96872300e-01,\n",
       "        2.35821060e-02,  4.68588260e-01,  1.68392090e-01, -6.90818550e-01,\n",
       "       -3.61105500e-02, -1.14341386e-01,  3.14037130e-02, -5.82755430e-02,\n",
       "       -2.03088670e-01, -7.18958000e-02,  1.36739540e-01,  6.89323500e-02,\n",
       "       -3.06005840e-01,  6.49216100e-02, -4.35307150e-01,  4.03725200e-02,\n",
       "       -3.53130370e-01,  1.10032305e-01, -3.58802860e-02, -4.97072670e-01,\n",
       "       -3.29097240e-01,  1.87469110e-01, -4.42122000e-02,  2.09332660e-01,\n",
       "        1.81546730e-01,  4.74228900e-01,  2.56354960e-01, -3.81504630e-01,\n",
       "       -1.71931880e-01,  1.38089570e-01, -1.32714240e-01, -5.44824000e-01,\n",
       "       -4.29731970e-01,  6.00716350e-01, -1.83736260e-01, -3.12206860e-01,\n",
       "        4.56217400e-02,  1.05036060e+00,  1.59803640e-01, -3.29034660e-01,\n",
       "        1.82069900e-01, -1.38326760e-01,  5.47459660e-01, -2.37329290e-01,\n",
       "        1.13873360e-01,  1.53738740e-01,  3.14401350e-02, -1.36476740e-01,\n",
       "        1.26814410e-01,  1.01653170e-02,  4.55338360e-01,  7.14279060e-01,\n",
       "       -2.39670680e-01,  5.49733200e-01, -6.21840200e-01, -4.21902000e-02,\n",
       "        1.30174600e-01,  4.29738000e-02,  3.39918600e-02,  1.11077990e-03,\n",
       "        4.40059270e-01, -2.62655440e-01,  5.59500630e-01, -7.50926300e-01,\n",
       "        3.56171580e-01, -1.74861820e-01, -3.16046120e-01, -6.06897700e-02,\n",
       "        2.38198920e-01, -7.81046150e-02,  3.53645400e-01,  2.95623150e-01,\n",
       "       -3.41648340e-01,  9.76943450e-02, -4.89530380e-01, -3.58462000e-01,\n",
       "       -3.36439000e-01,  4.64939700e-01,  2.96345320e-01,  6.90889000e-02,\n",
       "        5.75477500e-03,  5.62467870e-02, -5.85106400e-01,  7.87550960e-02,\n",
       "        2.05687100e-02, -1.07241340e-01,  3.82422150e-01, -4.91511450e-02,\n",
       "        2.20910800e-01, -6.97918400e-02,  2.22735930e-01, -3.03185280e-01,\n",
       "       -2.68759200e-02, -4.67494960e-01,  6.72057000e-02, -1.30268410e-01,\n",
       "        1.39918450e-01, -2.06790430e-01, -2.43040650e-01,  4.40537540e-01,\n",
       "        3.35280500e-01, -4.56028820e-01,  2.03928320e-01,  5.53468130e-02,\n",
       "        2.68382500e-01, -1.26431240e-01,  4.40042700e-01,  1.32963120e-01,\n",
       "       -3.52355100e-01, -7.75817860e-02, -4.88226530e-01,  1.37818260e-01,\n",
       "       -1.79392930e-01,  2.35610460e-01, -2.71397740e-01, -7.43899900e-02,\n",
       "        9.84324800e-02, -1.21690676e-01,  2.12142590e-01, -7.23218100e-02,\n",
       "        9.00619300e-03, -4.64825030e-02, -3.06141020e-01, -9.95536900e-02,\n",
       "        1.58794460e-01,  1.39050320e-01, -2.98317060e-02, -1.51323570e-01,\n",
       "       -3.45235050e-01,  7.65295250e-02,  3.72765780e-01,  4.22604140e-01,\n",
       "       -1.55146540e-01,  2.78305980e-01, -6.14458260e-01,  1.20588670e-01,\n",
       "       -3.93497470e-01, -4.66553200e-02,  6.44691900e-02, -1.73633020e-01,\n",
       "        1.34818600e-01, -2.20555110e-01,  1.87665050e-01, -4.94504540e-01,\n",
       "        3.12494370e-01, -1.61263760e-02,  1.50931880e-01,  1.94760530e-01,\n",
       "       -5.21986560e-02, -1.19889430e-01,  4.26618930e-01, -1.17165240e-01,\n",
       "       -2.45664970e-01, -8.12748100e-02,  3.01883900e-01,  4.06734760e-01,\n",
       "       -2.31532770e-01, -6.28649400e-01, -1.49909400e-01,  1.45796210e-01,\n",
       "        9.09992400e-03, -9.25468360e-02,  1.08067720e-01, -1.52320500e-01,\n",
       "        2.37321230e-01, -4.18761880e-01,  2.24849820e-01, -2.29809830e-03,\n",
       "        2.37791930e-01,  1.06143534e-01,  1.75165280e-01, -2.87342100e-01,\n",
       "        1.66862230e-01, -4.23401920e-01,  6.66687700e-02,  1.80612760e-01,\n",
       "       -2.67792730e-01, -6.10709450e-02, -2.85962500e-01, -2.12205700e-01,\n",
       "       -3.62321200e-01,  2.93388720e-01,  2.41581500e-01, -8.46944400e-02,\n",
       "       -9.85738300e-02, -6.32495800e-01,  6.20772660e-01, -9.87404300e-02,\n",
       "       -6.74467700e-01, -2.04847740e-01, -9.06434300e-02, -5.47551800e-01,\n",
       "        1.74144240e-01, -4.66198650e-01, -9.66474640e-02,  7.98277600e-02,\n",
       "       -3.06500940e-01, -1.14083510e-01, -3.51508320e-01,  2.61902150e-01,\n",
       "        3.77456200e-01,  4.89101320e-01,  5.69447300e-02, -5.84057100e-03,\n",
       "       -1.39455770e-01,  2.15218400e-01, -2.11418080e-01,  1.34993330e-01,\n",
       "        3.18772760e-01,  1.52233560e-01, -5.93194830e-03,  1.83161800e-01,\n",
       "        1.60117450e-01, -2.29056430e-01,  7.00216400e-03,  2.14186520e-01,\n",
       "       -3.47026900e-02, -3.73482000e-01,  2.07044750e-01, -1.77074500e-01,\n",
       "       -3.71965000e-01, -1.35178330e-01,  2.34698940e-01, -7.27614000e-02,\n",
       "       -1.58398480e-01, -4.48498700e-01,  3.11593100e-01,  3.25117230e-01,\n",
       "       -4.90671550e-01,  1.73751580e-02, -3.40301600e-01,  2.32466340e-01,\n",
       "       -1.98732900e-02, -6.83452800e-01, -3.77150200e-01,  8.67672700e-02,\n",
       "        7.98409300e-02,  2.60499620e-02,  2.10219500e-01, -1.61084770e-01,\n",
       "        9.98341600e-02,  2.81734100e-01, -1.13818780e-01, -1.14690610e-02,\n",
       "       -8.25852600e-02, -1.13605380e-01, -3.29732870e-01,  4.21534030e-02,\n",
       "       -2.03066450e-01,  1.42345640e-01,  1.83162390e-01,  3.17516030e-01,\n",
       "       -5.26656620e-02,  7.17285050e-02, -3.27064250e-02,  1.62390660e-01,\n",
       "       -1.63716960e-01, -2.75286530e-01, -8.07626100e-02,  3.30325480e-01,\n",
       "       -1.83889970e-01,  1.19244210e-01, -4.32670000e-01, -1.86949540e-01,\n",
       "        8.28408000e-01,  7.20225100e-02,  1.90734850e-01,  3.03030040e-01,\n",
       "        1.42058340e-01,  1.18690740e-01, -6.18960700e-01, -4.00831670e-01,\n",
       "       -2.33897050e-01,  5.10455370e-01,  5.52471340e-01,  1.21678890e-01,\n",
       "       -7.11787050e-02,  3.27699240e-01,  1.08268960e-01, -2.36220080e-02,\n",
       "       -3.84340030e-02,  2.40131020e-01,  1.42306610e-01,  6.70453160e-02,\n",
       "       -6.34659800e-01, -6.83052900e-02,  1.14210890e-01, -1.86470150e-01,\n",
       "       -5.24456460e-02, -1.51715530e-01,  1.17628805e-01, -9.70350900e-02,\n",
       "        4.90532600e-02,  1.30527590e-01,  1.48538840e-01,  7.09646940e-03,\n",
       "        1.31142500e-01,  1.07577910e-01,  3.66623160e-01,  3.78492440e-01,\n",
       "        2.27108690e-01,  8.65485550e-01,  2.89521400e-01,  1.75126760e-01,\n",
       "       -6.67359400e-01,  7.69890100e-02,  3.64880900e-02,  6.76159140e-01,\n",
       "        1.89075300e-01, -1.23251565e-01, -2.38852340e-01,  1.40748580e-03,\n",
       "       -2.10633230e-01, -2.21851260e-01, -4.53303120e-02,  5.95832000e-01,\n",
       "        3.67136630e-01, -1.78074390e-02, -8.57704600e-01, -9.50903600e-02,\n",
       "        2.09532700e-01, -3.64828260e-01, -4.20407700e-01,  2.62102130e-01,\n",
       "       -9.80526660e-02,  1.00143400e-01, -2.51825540e-01, -1.15241030e-01,\n",
       "        3.07798670e-02,  7.60911200e-01, -8.11627500e-02,  9.09545500e-02,\n",
       "       -2.98870220e-02, -7.01874900e-02,  3.65332720e-01, -2.26156770e-01,\n",
       "        6.89365450e-01, -1.31437270e-01,  3.48756340e-01,  1.75081060e-01,\n",
       "        2.95316250e-01,  2.06120480e-01,  2.51183570e-01,  1.79601240e-01,\n",
       "        3.88864000e-01,  5.91771500e-02, -7.23126160e-02,  7.57284760e-02,\n",
       "        6.82873900e-02,  1.03333110e-02,  9.11748350e-01,  1.29973350e-01,\n",
       "       -2.27259320e-01,  5.48960870e-03,  3.30623270e-01,  3.47738500e-01,\n",
       "        6.25555140e-02, -3.06045620e-01, -1.84564830e-01,  3.14390000e-02,\n",
       "        1.57415020e-01,  3.13199640e-01, -2.26465570e-01, -1.10225390e-01])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenation_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words processed:  29252\n"
     ]
    }
   ],
   "source": [
    "# Saving concatenated vectors\n",
    "\n",
    "embed_dict = {}\n",
    "for index in range(concatenation_matrix.shape[0]):\n",
    "    embed_dict[vocab_list[index]] = concatenation_matrix[index] \n",
    "                   \n",
    "embed.save_embeddings(embed_dict,'../Technodifacation/Embeddings/indic_300.ft_clean_300_concatenated.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: (29252, 600)\n",
      "\n",
      "Output Shape: (29252, 300)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Performing SVD on concatenated matrix (600 -> 300)\n",
    "\n",
    "svd = embed.perform_SVD(concatenation_matrix,num_components=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words processed:  29252\n"
     ]
    }
   ],
   "source": [
    "# Saving Results\n",
    "\n",
    "svd_dict = {}\n",
    "for index in range(svd.shape[0]):\n",
    "    svd_dict[vocab_list[index]] = svd[index] \n",
    "                   \n",
    "embed.save_embeddings(svd_dict,'../Technodifacation/Embeddings/SVD_indic_300.ft_clean_300_concatenated.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model\n",
      "29252  words loaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29252"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking saved files\n",
    "\n",
    "svd_embeddings = embed.load_embeddings('../Technodifacation/Embeddings/SVD_ft_clean_300.indic_300_concatenated.vec')\n",
    "len(svd_embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
