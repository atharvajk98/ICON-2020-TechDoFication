{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing import *\n",
    "from model import ml_classifier_model, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from joblib import dump\n",
    "from time import process_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>प्रा . प्रताप हरिदास : होय , मला वाटते की हा ए...</td>\n",
       "      <td>com_tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>तर , विशिष्ट गोष्टींद्वारे , ठराविक कायद्यांद्...</td>\n",
       "      <td>bioche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>- - - - - - - - - - - - - - - - - - - - - - - ...</td>\n",
       "      <td>cse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>तर , आपला अर्धा चिन्ह 9 वाजता असेल .</td>\n",
       "      <td>phy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>म्हणून , मी असे म्हणालो की जर शेकडो , हजारो कि...</td>\n",
       "      <td>phy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41992</th>\n",
       "      <td>जरी आपण डेटा कूटबद्ध केला , तरीही हा मुख्य व्य...</td>\n",
       "      <td>cse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41993</th>\n",
       "      <td>ते म्हणतात - \" ज्याला पाहण्यासाठी डोळे , ऎकण्य...</td>\n",
       "      <td>com_tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41994</th>\n",
       "      <td>प्रथम क्रोनोलॉजिकल , क्रॉनोलॉजी म्हणजे आपल्याल...</td>\n",
       "      <td>com_tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>त्या थोड्या तपशीलावर येईल , जेणेकरून संपूर्ण ग...</td>\n",
       "      <td>bioche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>आणि एका हॉटेलमध्ये त्यांनी एका स्विस रेस्ट्राम...</td>\n",
       "      <td>com_tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41997 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     label\n",
       "0      प्रा . प्रताप हरिदास : होय , मला वाटते की हा ए...  com_tech\n",
       "1      तर , विशिष्ट गोष्टींद्वारे , ठराविक कायद्यांद्...    bioche\n",
       "2      - - - - - - - - - - - - - - - - - - - - - - - ...       cse\n",
       "3                   तर , आपला अर्धा चिन्ह 9 वाजता असेल .       phy\n",
       "4      म्हणून , मी असे म्हणालो की जर शेकडो , हजारो कि...       phy\n",
       "...                                                  ...       ...\n",
       "41992  जरी आपण डेटा कूटबद्ध केला , तरीही हा मुख्य व्य...       cse\n",
       "41993  ते म्हणतात - \" ज्याला पाहण्यासाठी डोळे , ऎकण्य...  com_tech\n",
       "41994  प्रथम क्रोनोलॉजिकल , क्रॉनोलॉजी म्हणजे आपल्याल...  com_tech\n",
       "41995  त्या थोड्या तपशीलावर येईल , जेणेकरून संपूर्ण ग...    bioche\n",
       "41996  आणि एका हॉटेलमध्ये त्यांनी एका स्विस रेस्ट्राम...  com_tech\n",
       "\n",
       "[41997 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_path = \"../dataset/marathi-dataset/marathi-training-data.csv\"\n",
    "train_data = read_data(training_path)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "com_tech    17995\n",
       "phy          9656\n",
       "cse          9344\n",
       "bioche       5002\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 ची ओळ .</td>\n",
       "      <td>cse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>तर , ही एक टॉवर आहे जी टॉवरवर निश्चित केली जात...</td>\n",
       "      <td>phy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>तर , थ्रेडच्या परतीच्या स्थितीस पास करण्यासाठी...</td>\n",
       "      <td>cse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>आपण लोक शोधत आहात जे आपल्यासाठी काहीतरी करू शक...</td>\n",
       "      <td>com_tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>लिनक्स कर्नल अनुसूचीतकरणामध्ये अशी तंत्र असण्य...</td>\n",
       "      <td>cse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3775</th>\n",
       "      <td>नंतर वृद्धत्व , व्हॉट मोठ्या प्रमाणात फ्रॉन 12...</td>\n",
       "      <td>bioche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3776</th>\n",
       "      <td>आणि मग सुद्धा आपल्याला काही सेकंदांनंतर माहित ...</td>\n",
       "      <td>phy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3777</th>\n",
       "      <td>तर , आपण ELF शीर्षलेखासह प्रारंभ करू .</td>\n",
       "      <td>cse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3778</th>\n",
       "      <td>तर , त्या क्रॉस्टची जाडी आहे .</td>\n",
       "      <td>phy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779</th>\n",
       "      <td>तर , मला वाटते की ही माहिती अशी आहे की आपण एका...</td>\n",
       "      <td>phy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3780 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text     label\n",
       "0                                             1 ची ओळ .       cse\n",
       "1     तर , ही एक टॉवर आहे जी टॉवरवर निश्चित केली जात...       phy\n",
       "2     तर , थ्रेडच्या परतीच्या स्थितीस पास करण्यासाठी...       cse\n",
       "3     आपण लोक शोधत आहात जे आपल्यासाठी काहीतरी करू शक...  com_tech\n",
       "4     लिनक्स कर्नल अनुसूचीतकरणामध्ये अशी तंत्र असण्य...       cse\n",
       "...                                                 ...       ...\n",
       "3775  नंतर वृद्धत्व , व्हॉट मोठ्या प्रमाणात फ्रॉन 12...    bioche\n",
       "3776  आणि मग सुद्धा आपल्याला काही सेकंदांनंतर माहित ...       phy\n",
       "3777             तर , आपण ELF शीर्षलेखासह प्रारंभ करू .       cse\n",
       "3778                     तर , त्या क्रॉस्टची जाडी आहे .       phy\n",
       "3779  तर , मला वाटते की ही माहिती अशी आहे की आपण एका...       phy\n",
       "\n",
       "[3780 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_path = \"../dataset/marathi-dataset/marathi-validation-data.csv\"\n",
    "val_data = read_data(val_path)\n",
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "com_tech    1505\n",
       "phy          970\n",
       "cse          885\n",
       "bioche       420\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41997\n",
      "41997\n",
      "3780\n",
      "3780\n"
     ]
    }
   ],
   "source": [
    "x_train = train_data.text.apply(lambda x: clean_text(x)).values.tolist()\n",
    "y_train = train_data.label.values.tolist()\n",
    "x_val = val_data.text.apply(lambda x: clean_text(x)).values.tolist()\n",
    "y_val = val_data.label.values.tolist()\n",
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "print(len(x_val))\n",
    "print(len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "le, y_train, y_val = label_encoder(y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the BoW and TF-IDF representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52566"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_vectorizer, bow_x_train, bow_x_val = bow_vectorize(x_train, x_val, min_df=1)\n",
    "len(bow_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28981"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_bow_vectorizer, char_bow_x_train, char_bow_x_val = char_bow_vectorize(x_train, x_val, min_df=1)\n",
    "len(char_bow_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52566"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer, tfidf_x_train, tfidf_x_val = tfidf_vectorize(x_train, x_val, min_df=1)\n",
    "len(tfidf_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383099"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gram_tfidf_vectorizer, n_gram_tfidf_x_train, n_gram_tfidf_x_val = n_gram_tfidf_vectorize(x_train, x_val, min_df=1)\n",
    "len(n_gram_tfidf_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28981"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_tfidf_vectorizer, char_tfidf_x_train, char_tfidf_x_val = char_tfidf_vectorize(x_train, x_val)\n",
    "len(char_tfidf_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../tokenizers/char-tfidf-vectorizer-raw.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(bow_vectorizer, \"../tokenizers/bow-vectorizer-raw.pkl\")\n",
    "dump(char_bow_vectorizer, \"../tokenizers/char-bow-vectorizer-raw.pkl\")\n",
    "dump(tfidf_vectorizer, \"../tokenizers/tfidf-vectorizer-raw.pkl\")\n",
    "dump(n_gram_tfidf_vectorizer, \"../tokenizers/ngram-tfidf-vectorizer-raw.pkl\")\n",
    "dump(char_tfidf_vectorizer, \"../tokenizers/char-tfidf-vectorizer-raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = bow_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ai4Bharat Indic-Fasttext Marathi Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29155\n",
      "Total time taken:  11.362035446999997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(51800, 300)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = process_time()\n",
    "embedding_path1 = \"/home/eastwind/word-embeddings/fasttext/indicnlp.ft.mr.300.vec\"\n",
    "embedding_matrix1 = get_embedding_matrix(embedding_path1, vocab, 300)\n",
    "end = process_time()\n",
    "print(\"Total time taken: \", end-start)\n",
    "embedding_matrix1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41997, 300)\n",
      "(3780, 300)\n"
     ]
    }
   ],
   "source": [
    "ft_bow_x_train = get_sentence_embedding(embedding_matrix1, bow_x_train, 'bow')\n",
    "ft_bow_x_val = get_sentence_embedding(embedding_matrix1, bow_x_val, 'bow')\n",
    "print(ft_bow_x_train.shape)\n",
    "print(ft_bow_x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41997, 300)\n",
      "(3780, 300)\n"
     ]
    }
   ],
   "source": [
    "ft_tfidf_x_train = get_sentence_embedding(embedding_matrix1, tfidf_x_train, 'tfidf')\n",
    "ft_tfidf_x_val = get_sentence_embedding(embedding_matrix1, tfidf_x_val, 'tfidf')\n",
    "print(ft_tfidf_x_train.shape)\n",
    "print(ft_tfidf_x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain Specific fasttext Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51795\n",
      "Total time taken:  4.662203094000006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(51800, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = process_time()\n",
    "embedding_path2 = \"/home/eastwind/word-embeddings/fasttext/TechDofication.mr.cleaned.ft.skipgram.d300.vec\"\n",
    "embedding_matrix2 = get_embedding_matrix(embedding_path2, vocab, 300)\n",
    "end = process_time()\n",
    "print(\"Total time taken: \", end-start)\n",
    "embedding_matrix2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41997, 300)\n",
      "(3780, 300)\n"
     ]
    }
   ],
   "source": [
    "ds_bow_x_train = get_sentence_embedding(embedding_matrix2, bow_x_train, 'bow')\n",
    "ds_bow_x_val = get_sentence_embedding(embedding_matrix2, bow_x_val, 'bow')\n",
    "print(ds_bow_x_train.shape)\n",
    "print(ds_bow_x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41997, 300)\n",
      "(3780, 300)\n"
     ]
    }
   ],
   "source": [
    "ds_tfidf_x_train = get_sentence_embedding(embedding_matrix2, tfidf_x_train, 'tfidf')\n",
    "ds_tfidf_x_val = get_sentence_embedding(embedding_matrix2, tfidf_x_val, 'tfidf')\n",
    "print(ds_tfidf_x_train.shape)\n",
    "print(ds_tfidf_x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.8674603174603175\n",
      "\n",
      "Precision:  [0.92038217 0.84232868 0.91625616 0.85273632]\n",
      "Average Precision:  0.8829258314248659\n",
      "\n",
      "Recall:  [0.68809524 0.92292359 0.84067797 0.88350515]\n",
      "Average nRecall:  0.8338004867189939\n",
      "\n",
      "F1-Score:  [0.78746594 0.8807863  0.87684148 0.8678481 ]\n",
      "Average F1-Score:  0.8532354573502416\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Count Vectors\n",
    "NB_bow, NB_bow_predictions = ml_classifier_model(MultinomialNB(), \n",
    "                                                  bow_x_train, bow_x_val, \n",
    "                                                  y_train, y_val)\n",
    "\n",
    "acc, precision, recall, f1 = classification_report(y_val, NB_bow_predictions)\n",
    "print(\"Validation Accuracy: \", acc)\n",
    "print(\"\\nPrecision: \", precision)\n",
    "print(\"Average Precision: \", np.mean(precision))\n",
    "print(\"\\nRecall: \", recall)\n",
    "print(\"Average nRecall: \", np.mean(recall))\n",
    "print(\"\\nF1-Score: \", f1)\n",
    "print(\"Average F1-Score: \", np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.8161375661375662\n",
      "\n",
      "Precision:  [0.73860911 0.83279115 0.8200692  0.81960375]\n",
      "Average Precision:  0.8027683055916047\n",
      "\n",
      "Recall:  [0.73333333 0.85049834 0.80338983 0.81030928]\n",
      "Average nRecall:  0.7993826952656888\n",
      "\n",
      "F1-Score:  [0.73596177 0.84155161 0.81164384 0.81493002]\n",
      "Average F1-Score:  0.8010218075426877\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on character level Count Vectors\n",
    "NB_char_bow, NB_char_bow_predictions = ml_classifier_model(MultinomialNB(), \n",
    "                                                           char_bow_x_train, char_bow_x_val, \n",
    "                                                           y_train, y_val)\n",
    "\n",
    "acc, precision, recall, f1 = classification_report(y_val, NB_char_bow_predictions)\n",
    "print(\"Validation Accuracy: \", acc)\n",
    "print(\"\\nPrecision: \", precision)\n",
    "print(\"Average Precision: \", np.mean(precision))\n",
    "print(\"\\nRecall: \", recall)\n",
    "print(\"Average nRecall: \", np.mean(recall))\n",
    "print(\"\\nF1-Score: \", f1)\n",
    "print(\"Average F1-Score: \", np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.7716931216931217\n",
      "\n",
      "Precision:  [1.         0.66696997 0.95761381 0.86934673]\n",
      "Average Precision:  0.8734826302818676\n",
      "\n",
      "Recall:  [0.3547619  0.97408638 0.68926554 0.71340206]\n",
      "Average nRecall:  0.6828789705195701\n",
      "\n",
      "F1-Score:  [0.52372583 0.79179044 0.80157687 0.78369196]\n",
      "Average F1-Score:  0.7251962766868902\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on TF-IDF\n",
    "NB_tfidf, NB_tfidf_predictions = ml_classifier_model(MultinomialNB(), \n",
    "                                                      tfidf_x_train, tfidf_x_val, \n",
    "                                                      y_train, y_val)\n",
    "\n",
    "acc, precision, recall, f1 = classification_report(y_val, NB_tfidf_predictions)\n",
    "print(\"Validation Accuracy: \", acc)\n",
    "print(\"\\nPrecision: \", precision)\n",
    "print(\"Average Precision: \", np.mean(precision))\n",
    "print(\"\\nRecall: \", recall)\n",
    "print(\"Average nRecall: \", np.mean(recall))\n",
    "print(\"\\nF1-Score: \", f1)\n",
    "print(\"Average F1-Score: \", np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.6198412698412699\n",
      "\n",
      "Precision:  [1.         0.52018093 0.96632124 0.90546218]\n",
      "Average Precision:  0.8479910902238814\n",
      "\n",
      "Recall:  [0.1047619  0.99335548 0.42146893 0.4443299 ]\n",
      "Average nRecall:  0.49097905248759205\n",
      "\n",
      "F1-Score:  [0.18965517 0.68280429 0.58693942 0.59612725]\n",
      "Average F1-Score:  0.5138815327480567\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on n-gram TF-IDF\n",
    "NB_ngram_tfidf, NB_ngram_predictions = ml_classifier_model(MultinomialNB(), \n",
    "                                                           n_gram_tfidf_x_train, n_gram_tfidf_x_val, \n",
    "                                                           y_train, y_val)\n",
    "\n",
    "acc, precision, recall, f1 = classification_report(y_val, NB_ngram_predictions)\n",
    "print(\"Validation Accuracy: \", acc)\n",
    "print(\"\\nPrecision: \", precision)\n",
    "print(\"Average Precision: \", np.mean(precision))\n",
    "print(\"\\nRecall: \", recall)\n",
    "print(\"Average nRecall: \", np.mean(recall))\n",
    "print(\"\\nF1-Score: \", f1)\n",
    "print(\"Average F1-Score: \", np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.7693121693121693\n",
      "\n",
      "Precision:  [0.95652174 0.68279828 0.89985486 0.83780488]\n",
      "Average Precision:  0.8442449385835413\n",
      "\n",
      "Recall:  [0.41904762 0.94684385 0.70056497 0.70824742]\n",
      "Average nRecall:  0.6936759668250105\n",
      "\n",
      "F1-Score:  [0.58278146 0.79342984 0.78780178 0.76759777]\n",
      "Average F1-Score:  0.7329027113305022\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on character-level TF-IDF\n",
    "NB_char_tfidf, NB_char_predictions = ml_classifier_model(MultinomialNB(), \n",
    "                                                         char_tfidf_x_train, char_tfidf_x_val, \n",
    "                                                         y_train, y_val)\n",
    "\n",
    "acc, precision, recall, f1 = classification_report(y_val, NB_char_predictions)\n",
    "print(\"Validation Accuracy: \", acc)\n",
    "print(\"\\nPrecision: \", precision)\n",
    "print(\"Average Precision: \", np.mean(precision))\n",
    "print(\"\\nRecall: \", recall)\n",
    "print(\"Average nRecall: \", np.mean(recall))\n",
    "print(\"\\nF1-Score: \", f1)\n",
    "print(\"Average F1-Score: \", np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/naive-bayes/NB-char-tfidf-raw.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(NB_bow, \"../models/naive-bayes/NB-bow-raw.pkl\")\n",
    "dump(NB_char_bow, \"../models/naive-bayes/NB-char-bow-raw.pkl\")\n",
    "dump(NB_tfidf, \"../models/naive-bayes/NB-tfidf-raw.pkl\")\n",
    "dump(NB_ngram_tfidf, \"../models/naive-bayes/NB-ngram-tfidf-raw.pkl\")\n",
    "dump(NB_char_tfidf, \"../models/naive-bayes/NB-char-tfidf-raw.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statsitical word representation approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.8576719576719577\n",
      "\n",
      "Precision:  [0.84254144 0.85759695 0.87514451 0.84795918]\n",
      "Average Precision:  0.8558105193285293\n",
      "\n",
      "Recall:  [0.72619048 0.89634551 0.85536723 0.85670103]\n",
      "Average nRecall:  0.8336510634267239\n",
      "\n",
      "F1-Score:  [0.78005115 0.87654321 0.86514286 0.85230769]\n",
      "Average F1-Score:  0.8435112275555583\n"
     ]
    }
   ],
   "source": [
    "# Linear SVC on Count Vectors\n",
    "LSVC_bow, LSVC_bow_predictions = ml_classifier_model(LinearSVC(max_iter=2000), \n",
    "                                                     bow_x_train, bow_x_val, \n",
    "                                                     y_train, y_val)\n",
    "\n",
    "acc, precision, recall, f1 = classification_report(y_val, LSVC_bow_predictions)\n",
    "print(\"Validation Accuracy: \", acc)\n",
    "print(\"\\nPrecision: \", precision)\n",
    "print(\"Average Precision: \", np.mean(precision))\n",
    "print(\"\\nRecall: \", recall)\n",
    "print(\"Average nRecall: \", np.mean(recall))\n",
    "print(\"\\nF1-Score: \", f1)\n",
    "print(\"Average F1-Score: \", np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.861904761904762\n",
      "\n",
      "Precision:  [0.80916031 0.8771022  0.87514318 0.84710744]\n",
      "Average Precision:  0.8521282817513447\n",
      "\n",
      "Recall:  [0.75714286 0.90099668 0.86327684 0.84536082]\n",
      "Average nRecall:  0.8416942989460453\n",
      "\n",
      "F1-Score:  [0.78228782 0.88888889 0.86916951 0.84623323]\n",
      "Average F1-Score:  0.8466448631772533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eastwind/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "# Linear SVC on character-level Count Vectors\n",
    "LSVC_char_bow, LSVC_char_bow_predictions = ml_classifier_model(LinearSVC(max_iter=2000), \n",
    "                                                               char_bow_x_train, char_bow_x_val, \n",
    "                                                               y_train, y_val)\n",
    "\n",
    "acc, precision, recall, f1 = classification_report(y_val, LSVC_char_bow_predictions)\n",
    "print(\"Validation Accuracy: \", acc)\n",
    "print(\"\\nPrecision: \", precision)\n",
    "print(\"Average Precision: \", np.mean(precision))\n",
    "print(\"\\nRecall: \", recall)\n",
    "print(\"Average nRecall: \", np.mean(recall))\n",
    "print(\"\\nF1-Score: \", f1)\n",
    "print(\"Average F1-Score: \", np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.8817460317460317\n",
      "\n",
      "Precision:  [0.88135593 0.871875   0.90592334 0.87668394]\n",
      "Average Precision:  0.8839595537437399\n",
      "\n",
      "Recall:  [0.74285714 0.9269103  0.88135593 0.87216495]\n",
      "Average nRecall:  0.8558220806293658\n",
      "\n",
      "F1-Score:  [0.80620155 0.89855072 0.89347079 0.8744186 ]\n",
      "Average F1-Score:  0.868160417513612\n"
     ]
    }
   ],
   "source": [
    "# Linear SVC on TF-IDF\n",
    "LSVC_tfidf, LSVC_tfidf_predictions = ml_classifier_model(LinearSVC(), \n",
    "                                                         tfidf_x_train, tfidf_x_val, \n",
    "                                                         y_train, y_val)\n",
    "\n",
    "acc, precision, recall, f1 = classification_report(y_val, LSVC_tfidf_predictions)\n",
    "print(\"Validation Accuracy: \", acc)\n",
    "print(\"\\nPrecision: \", precision)\n",
    "print(\"Average Precision: \", np.mean(precision))\n",
    "print(\"\\nRecall: \", recall)\n",
    "print(\"Average nRecall: \", np.mean(recall))\n",
    "print(\"\\nF1-Score: \", f1)\n",
    "print(\"Average F1-Score: \", np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.8727513227513227\n",
      "\n",
      "Precision:  [0.89367816 0.85067319 0.89647059 0.88185654]\n",
      "Average Precision:  0.8806696209634165\n",
      "\n",
      "Recall:  [0.74047619 0.92358804 0.86101695 0.86185567]\n",
      "Average nRecall:  0.8467342123997338\n",
      "\n",
      "F1-Score:  [0.80989583 0.88563237 0.87838617 0.8717414 ]\n",
      "Average F1-Score:  0.861413941191252\n"
     ]
    }
   ],
   "source": [
    "# Linear SVC on n-gram TF-IDF\n",
    "LSVC_ngram_tfidf, LSVC_ngram_tfidf_predictions = ml_classifier_model(LinearSVC(), \n",
    "                                                                     n_gram_tfidf_x_train, n_gram_tfidf_x_val, \n",
    "                                                                     y_train, y_val)\n",
    "\n",
    "acc, precision, recall, f1 = classification_report(y_val, LSVC_ngram_tfidf_predictions)\n",
    "print(\"Validation Accuracy: \", acc)\n",
    "print(\"\\nPrecision: \", precision)\n",
    "print(\"Average Precision: \", np.mean(precision))\n",
    "print(\"\\nRecall: \", recall)\n",
    "print(\"Average nRecall: \", np.mean(recall))\n",
    "print(\"\\nF1-Score: \", f1)\n",
    "print(\"Average F1-Score: \", np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.8878306878306879\n",
      "\n",
      "Precision:  [0.9154519  0.87352759 0.89874858 0.89206349]\n",
      "Average Precision:  0.8949478883453471\n",
      "\n",
      "Recall:  [0.74761905 0.93621262 0.89265537 0.86907216]\n",
      "Average nRecall:  0.8613898010959643\n",
      "\n",
      "F1-Score:  [0.82306684 0.90378448 0.89569161 0.88041775]\n",
      "Average F1-Score:  0.8757401707977434\n"
     ]
    }
   ],
   "source": [
    "# Linear SVC on character-level TF-IDF\n",
    "LSVC_char_tfidf, LSVC_char_tfidf_predictions = ml_classifier_model(LinearSVC(), \n",
    "                                                                   char_tfidf_x_train, char_tfidf_x_val, \n",
    "                                                                   y_train, y_val)\n",
    "\n",
    "acc, precision, recall, f1 = classification_report(y_val, LSVC_char_tfidf_predictions)\n",
    "print(\"Validation Accuracy: \", acc)\n",
    "print(\"\\nPrecision: \", precision)\n",
    "print(\"Average Precision: \", np.mean(precision))\n",
    "print(\"\\nRecall: \", recall)\n",
    "print(\"Average nRecall: \", np.mean(recall))\n",
    "print(\"\\nF1-Score: \", f1)\n",
    "print(\"Average F1-Score: \", np.mean(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indic-Word Embedding bassed approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eastwind/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.7775132275132275\n",
      "\n",
      "Precision:  [0.78594249 0.77227139 0.78103044 0.78104575]\n",
      "Average Precision:  0.780072518760579\n",
      "\n",
      "Recall:  [0.58571429 0.86976744 0.75367232 0.73917526]\n",
      "Average nRecall:  0.7370823254227226\n",
      "\n",
      "F1-Score:  [0.67121419 0.818125   0.76710753 0.7595339 ]\n",
      "Average F1-Score:  0.7539951549093648\n"
     ]
    }
   ],
   "source": [
    "# Linear SVC on Count Vectors based indic fasttext word embeddings\n",
    "LSVC_ft_bow, LSVC_ft_bow_predictions = ml_classifier_model(LinearSVC(max_iter=5000), \n",
    "                                                           ft_bow_x_train, ft_bow_x_val, \n",
    "                                                           y_train, y_val)\n",
    "\n",
    "acc, precision, recall, f1 = classification_report(y_val, LSVC_ft_bow_predictions)\n",
    "print(\"Validation Accuracy: \", acc)\n",
    "print(\"\\nPrecision: \", precision)\n",
    "print(\"Average Precision: \", np.mean(precision))\n",
    "print(\"\\nRecall: \", recall)\n",
    "print(\"Average nRecall: \", np.mean(recall))\n",
    "print(\"\\nF1-Score: \", f1)\n",
    "print(\"Average F1-Score: \", np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken:  199.24928511500002\n",
      "\n",
      "Validation Accuracy:  0.7735449735449735\n",
      "\n",
      "Precision:  [0.76380368 0.77008798 0.77842907 0.77901786]\n",
      "Average Precision:  0.7728346471302543\n",
      "\n",
      "Recall:  [0.59285714 0.87242525 0.75028249 0.71958763]\n",
      "Average nRecall:  0.733788126692066\n",
      "\n",
      "F1-Score:  [0.66756032 0.81806854 0.76409666 0.74812433]\n",
      "Average F1-Score:  0.7494624626225255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eastwind/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "# Linear SVC on TF-IDF based indic fasttext word embeddings\n",
    "start = process_time()\n",
    "LSVC_ft_tfidf, LSVC_ft_tfidf_predictions = ml_classifier_model(LinearSVC(max_iter=2000), \n",
    "                                                               ft_tfidf_x_train, ft_tfidf_x_val, \n",
    "                                                               y_train, y_val)\n",
    "\n",
    "acc, precision, recall, f1 = classification_report(y_val, LSVC_ft_tfidf_predictions)\n",
    "end = process_time()\n",
    "print(\"Total time taken: \", end-start)\n",
    "print(\"\\nValidation Accuracy: \", acc)\n",
    "print(\"\\nPrecision: \", precision)\n",
    "print(\"Average Precision: \", np.mean(precision))\n",
    "print(\"\\nRecall: \", recall)\n",
    "print(\"Average nRecall: \", np.mean(recall))\n",
    "print(\"\\nF1-Score: \", f1)\n",
    "print(\"Average F1-Score: \", np.mean(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Specific Word Embedding bassed approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken:  144.21333912900002\n",
      "\n",
      "Validation Accuracy:  0.8452380952380952\n",
      "\n",
      "Precision:  [0.85087719 0.82685298 0.88809524 0.83718487]\n",
      "Average Precision:  0.8507525704852511\n",
      "\n",
      "Recall:  [0.69285714 0.90431894 0.84293785 0.82164948]\n",
      "Average nRecall:  0.8154408543444116\n",
      "\n",
      "F1-Score:  [0.76377953 0.86385275 0.86492754 0.82934443]\n",
      "Average F1-Score:  0.8304760604584049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eastwind/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "# Linear SVC on Count Vectors based domain specific word embeddings\n",
    "start = process_time()\n",
    "LSVC_ds_bow, LSVC_ds_bow_predictions = ml_classifier_model(LinearSVC(max_iter=2000), \n",
    "                                                           ds_bow_x_train, ds_bow_x_val, \n",
    "                                                           y_train, y_val)\n",
    "\n",
    "acc, precision, recall, f1 = classification_report(y_val, LSVC_ds_bow_predictions)\n",
    "end = process_time()\n",
    "print(\"Total time taken: \", end-start)\n",
    "print(\"\\nValidation Accuracy: \", acc)\n",
    "print(\"\\nPrecision: \", precision)\n",
    "print(\"Average Precision: \", np.mean(precision))\n",
    "print(\"\\nRecall: \", recall)\n",
    "print(\"Average nRecall: \", np.mean(recall))\n",
    "print(\"\\nF1-Score: \", f1)\n",
    "print(\"Average F1-Score: \", np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken:  147.42722584299997\n",
      "\n",
      "Validation Accuracy:  0.8494708994708995\n",
      "\n",
      "Precision:  [0.88588589 0.81932021 0.89366786 0.85101822]\n",
      "Average Precision:  0.8624730456894688\n",
      "\n",
      "Recall:  [0.70238095 0.91295681 0.84519774 0.8185567 ]\n",
      "Average nRecall:  0.819773051039026\n",
      "\n",
      "F1-Score:  [0.78353254 0.86360779 0.86875726 0.83447189]\n",
      "Average F1-Score:  0.8375923689642764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eastwind/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "# Linear SVC on TF-IDF based domain specific word embeddings\n",
    "start = process_time()\n",
    "LSVC_ds_tfidf, LSVC_ds_tfidf_predictions = ml_classifier_model(LinearSVC(max_iter=2000), \n",
    "                                                               ds_tfidf_x_train, ds_tfidf_x_val, \n",
    "                                                               y_train, y_val)\n",
    "\n",
    "acc, precision, recall, f1 = classification_report(y_val, LSVC_ds_tfidf_predictions)\n",
    "end = process_time()\n",
    "print(\"Total time taken: \", end-start)\n",
    "print(\"\\nValidation Accuracy: \", acc)\n",
    "print(\"\\nPrecision: \", precision)\n",
    "print(\"Average Precision: \", np.mean(precision))\n",
    "print(\"\\nRecall: \", recall)\n",
    "print(\"Average nRecall: \", np.mean(recall))\n",
    "print(\"\\nF1-Score: \", f1)\n",
    "print(\"Average F1-Score: \", np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/linear-svc/LSVC-ds-tfidf.pkl']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(LSVC_bow, \"../models/linear-svc/LSVC-bow-raw.pkl\")\n",
    "dump(LSVC_char_bow, \"../models/linear-svc/LSVC-char-bow-raw.pkl\")\n",
    "dump(LSVC_tfidf, \"../models/linear-svc/LSVC-tfidf-raw.pkl\")\n",
    "dump(LSVC_ngram_tfidf, \"../models/linear-svc/LSVC-ngram-tfidf-raw.pkl\")\n",
    "dump(LSVC_char_tfidf, \"../models/linear-svc/LSVC-char-tfidf-raw.pkl\")\n",
    "dump(LSVC_ft_bow, \"../models/linear-svc/LSVC-indic-bow-raw.pkl\")\n",
    "dump(LSVC_ft_tfidf, \"../models/linear-svc/LSVC-indic-tfidf-raw.pkl\")\n",
    "dump(LSVC_ds_bow, \"../models/linear-svc/LSVC-ds-bow-raw.pkl\")\n",
    "dump(LSVC_ds_tfidf, \"../models/linear-svc/LSVC-ds-tfidf-raw.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical word representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.4714285714285714\n",
      "\n",
      "Precision:  [0.28853755 0.56741214 0.5511811  0.40512048]\n",
      "Average Precision:  0.4530628185680275\n",
      "\n",
      "Recall:  [0.34761905 0.59003322 0.23728814 0.55463918]\n",
      "Average nRecall:  0.43239489526534053\n",
      "\n",
      "F1-Score:  [0.31533477 0.57850163 0.33175355 0.46823325]\n",
      "Average F1-Score:  0.42345580067153477\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors on  Count Vectors\n",
    "knn_bow, knn_bow_predictions = ml_classifier_model(KNeighborsClassifier(n_neighbors=7), \n",
    "                                                   bow_x_train, bow_x_val, \n",
    "                                                   y_train, y_val)\n",
    "\n",
    "acc, precision, recall, f1 = classification_report(y_val, knn_bow_predictions)\n",
    "print(\"Validation Accuracy: \", acc)\n",
    "print(\"\\nPrecision: \", precision)\n",
    "print(\"Average Precision: \", np.mean(precision))\n",
    "print(\"\\nRecall: \", recall)\n",
    "print(\"Average nRecall: \", np.mean(recall))\n",
    "print(\"\\nF1-Score: \", f1)\n",
    "print(\"Average F1-Score: \", np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.6060846560846561\n",
      "\n",
      "Precision:  [0.55483871 0.61638633 0.68630573 0.55255255]\n",
      "Average Precision:  0.6025208303388485\n",
      "\n",
      "Recall:  [0.40952381 0.75481728 0.48700565 0.56907216]\n",
      "Average nRecall:  0.5551047249843214\n",
      "\n",
      "F1-Score:  [0.47123288 0.6786141  0.56972902 0.56069071]\n",
      "Average F1-Score:  0.5700666739562386\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors on  character level Count Vectors\n",
    "knn_char_bow, knn_char_bow_predictions = ml_classifier_model(KNeighborsClassifier(n_neighbors=7), \n",
    "                                                             char_bow_x_train, char_bow_x_val, \n",
    "                                                             y_train, y_val)\n",
    "\n",
    "acc, precision, recall, f1 = classification_report(y_val, knn_char_bow_predictions)\n",
    "print(\"Validation Accuracy: \", acc)\n",
    "print(\"\\nPrecision: \", precision)\n",
    "print(\"Average Precision: \", np.mean(precision))\n",
    "print(\"\\nRecall: \", recall)\n",
    "print(\"Average nRecall: \", np.mean(recall))\n",
    "print(\"\\nF1-Score: \", f1)\n",
    "print(\"Average F1-Score: \", np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.344973544973545\n",
      "\n",
      "Precision:  [0.15348837 0.44532131 0.625      0.28912876]\n",
      "Average Precision:  0.37823460963647915\n",
      "\n",
      "Recall:  [0.23571429 0.52491694 0.04519774 0.38659794]\n",
      "Average nRecall:  0.29810672687330114\n",
      "\n",
      "F1-Score:  [0.18591549 0.48185422 0.08429926 0.3308337 ]\n",
      "Average F1-Score:  0.27072567002856734\n"
     ]
    }
   ],
   "source": [
    "# Random Forest on TF-IDF\n",
    "knn_tfidf, knn_tfidf_predictions = ml_classifier_model(KNeighborsClassifier(n_neighbors=7), \n",
    "                                                       tfidf_x_train, tfidf_x_val, \n",
    "                                                       y_train, y_val)\n",
    "\n",
    "acc, precision, recall, f1 = classification_report(y_val, knn_tfidf_predictions)\n",
    "print(\"Validation Accuracy: \", acc)\n",
    "print(\"\\nPrecision: \", precision)\n",
    "print(\"Average Precision: \", np.mean(precision))\n",
    "print(\"\\nRecall: \", recall)\n",
    "print(\"Average nRecall: \", np.mean(recall))\n",
    "print(\"\\nF1-Score: \", f1)\n",
    "print(\"Average F1-Score: \", np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.34973544973544973\n",
      "\n",
      "Precision:  [0.09322034 0.41794514 0.4375     0.28434974]\n",
      "Average Precision:  0.30825380590342877\n",
      "\n",
      "Recall:  [0.05238095 0.59734219 0.01581921 0.39896907]\n",
      "Average nRecall:  0.26612785656911975\n",
      "\n",
      "F1-Score:  [0.06707317 0.49179431 0.03053435 0.33204633]\n",
      "Average F1-Score:  0.23036204116129455\n"
     ]
    }
   ],
   "source": [
    "# Random Forest on n-gram TF-IDF\n",
    "knn_ngram_tfidf, knn_ngram_tfidf_predictions = ml_classifier_model(KNeighborsClassifier(n_neighbors=7), \n",
    "                                                                   n_gram_tfidf_x_train, n_gram_tfidf_x_val, \n",
    "                                                                   y_train, y_val)\n",
    "\n",
    "acc, precision, recall, f1 = classification_report(y_val, knn_ngram_tfidf_predictions)\n",
    "print(\"Validation Accuracy: \", acc)\n",
    "print(\"\\nPrecision: \", precision)\n",
    "print(\"Average Precision: \", np.mean(precision))\n",
    "print(\"\\nRecall: \", recall)\n",
    "print(\"Average nRecall: \", np.mean(recall))\n",
    "print(\"\\nF1-Score: \", f1)\n",
    "print(\"Average F1-Score: \", np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.40185185185185185\n",
      "\n",
      "Precision:  [0.21035599 0.48212157 0.84137931 0.3420463 ]\n",
      "Average Precision:  0.4689757934781863\n",
      "\n",
      "Recall:  [0.30952381 0.53754153 0.13785311 0.47216495]\n",
      "Average nRecall:  0.3642708483903133\n",
      "\n",
      "F1-Score:  [0.2504817  0.50832548 0.2368932  0.39670853]\n",
      "Average F1-Score:  0.34810222759790443\n"
     ]
    }
   ],
   "source": [
    "# Random Forest on character-level TF-IDF\n",
    "knn_char_tfidf, knn_char_tfidf_predictions = ml_classifier_model(KNeighborsClassifier(n_neighbors=7), \n",
    "                                                                 char_tfidf_x_train, char_tfidf_x_val, \n",
    "                                                                 y_train, y_val)\n",
    "\n",
    "acc, precision, recall, f1 = classification_report(y_val, knn_char_tfidf_predictions)\n",
    "print(\"Validation Accuracy: \", acc)\n",
    "print(\"\\nPrecision: \", precision)\n",
    "print(\"Average Precision: \", np.mean(precision))\n",
    "print(\"\\nRecall: \", recall)\n",
    "print(\"Average nRecall: \", np.mean(recall))\n",
    "print(\"\\nF1-Score: \", f1)\n",
    "print(\"Average F1-Score: \", np.mean(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indic-fasttext Word Embeddings based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.7431216931216931\n",
      "\n",
      "Precision:  [0.66582915 0.76613886 0.7979798  0.70009551]\n",
      "Average Precision:  0.7325108274367539\n",
      "\n",
      "Recall:  [0.63095238 0.8358804  0.62485876 0.7556701 ]\n",
      "Average nRecall:  0.7118404099446018\n",
      "\n",
      "F1-Score:  [0.64792176 0.79949158 0.7008872  0.72682201]\n",
      "Average F1-Score:  0.7187806378873858\n"
     ]
    }
   ],
   "source": [
    "# KNN on Indic fasttext embeddings (BoW)\n",
    "knn_bow_indic, knn_bow_indic_predictions = ml_classifier_model(KNeighborsClassifier(n_neighbors=7), \n",
    "                                                                 ft_bow_x_train, ft_bow_x_val, \n",
    "                                                                 y_train, y_val)\n",
    "\n",
    "acc, precision, recall, f1 = classification_report(y_val, knn_bow_indic_predictions)\n",
    "print(\"Validation Accuracy: \", acc)\n",
    "print(\"\\nPrecision: \", precision)\n",
    "print(\"Average Precision: \", np.mean(precision))\n",
    "print(\"\\nRecall: \", recall)\n",
    "print(\"Average nRecall: \", np.mean(recall))\n",
    "print(\"\\nF1-Score: \", f1)\n",
    "print(\"Average F1-Score: \", np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.746031746031746\n",
      "\n",
      "Precision:  [0.62276786 0.79260238 0.6884273  0.79925651]\n",
      "Average Precision:  0.7257635100573656\n",
      "\n",
      "Recall:  [0.66428571 0.79734219 0.78644068 0.66494845]\n",
      "Average nRecall:  0.7282542596377733\n",
      "\n",
      "F1-Score:  [0.64285714 0.79496522 0.73417722 0.7259426 ]\n",
      "Average F1-Score:  0.7244855445515201\n"
     ]
    }
   ],
   "source": [
    "# KNN on Indic fasttext embeddings (TF-IDF)\n",
    "knn_tfidf_indic, knn_tfidf_indic_predictions = ml_classifier_model(KNeighborsClassifier(n_neighbors=7), \n",
    "                                                                 ft_tfidf_x_train, ft_tfidf_x_val, \n",
    "                                                                 y_train, y_val)\n",
    "\n",
    "acc, precision, recall, f1 = classification_report(y_val, knn_tfidf_indic_predictions)\n",
    "print(\"Validation Accuracy: \", acc)\n",
    "print(\"\\nPrecision: \", precision)\n",
    "print(\"Average Precision: \", np.mean(precision))\n",
    "print(\"\\nRecall: \", recall)\n",
    "print(\"Average nRecall: \", np.mean(recall))\n",
    "print(\"\\nF1-Score: \", f1)\n",
    "print(\"Average F1-Score: \", np.mean(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Specific Word Embeddings based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN on Domain Specific fasttext embeddings (BoW)\n",
    "index = [3, 5, 7, 9, 11, 13, 15]\n",
    "model = []\n",
    "accuracy = []\n",
    "f1_score = []\n",
    "for i in index:\n",
    "    knn_bow_ds, knn_bow_ds_predictions = ml_classifier_model(KNeighborsClassifier(n_neighbors=i), \n",
    "                                                             ds_bow_x_train, ds_bow_x_val, \n",
    "                                                             y_train, y_val)\n",
    "\n",
    "    acc, precision, recall, f1 = classification_report(y_val, knn_bow_ds_predictions)\n",
    "    \n",
    "    model.append(knn_bow_ds)\n",
    "    accuracy.append(acc)\n",
    "    f1_score.append(f1)\n",
    "#print(\"Validation Accuracy: \", acc)\n",
    "#print(\"\\nPrecision: \", precision)\n",
    "#print(\"Average Precision: \", np.mean(precision))\n",
    "#print(\"\\nRecall: \", recall)\n",
    "#print(\"Average nRecall: \", np.mean(recall))\n",
    "#print(\"\\nF1-Score: \", f1)\n",
    "#print(\"Average F1-Score: \", np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors: 3, accuracy: 0.7706349206349207, f11-score: 0.7564729241458641\n",
      "Neighbors: 5, accuracy: 0.785978835978836, f11-score: 0.779420937691388\n",
      "Neighbors: 7, accuracy: 0.7854497354497354, f11-score: 0.7782878810166497\n",
      "Neighbors: 9, accuracy: 0.7894179894179895, f11-score: 0.7821699529626662\n",
      "Neighbors: 11, accuracy: 0.785978835978836, f11-score: 0.7791622929531717\n",
      "Neighbors: 13, accuracy: 0.7828042328042328, f11-score: 0.7737338880112158\n",
      "Neighbors: 15, accuracy: 0.782010582010582, f11-score: 0.7718467622580447\n"
     ]
    }
   ],
   "source": [
    "for i, a, f, in list(zip(index, accuracy, f1_score)):\n",
    "    print(\"Neighbors: {}, accuracy: {}, f11-score: {}\".format(i, a, np.mean(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:  3\n",
      "Done:  5\n",
      "Done:  7\n",
      "Done:  9\n",
      "Done:  11\n"
     ]
    }
   ],
   "source": [
    "# KNN on Domain Specific fasttext embeddings (TF-IDF)\n",
    "index = [3, 5, 7, 9, 11, 13, 15]\n",
    "model = []\n",
    "accuracy = []\n",
    "f1_score = []\n",
    "for i in index:\n",
    "    knn_tfidf_ds, knn_tfidf_ds_predictions = ml_classifier_model(KNeighborsClassifier(n_neighbors=11), \n",
    "                                                                 ds_tfidf_x_train, ds_tfidf_x_val, \n",
    "                                                                 y_train, y_val)\n",
    "\n",
    "    acc, precision, recall, f1 = classification_report(y_val, knn_tfidf_ds_predictions)\n",
    "    \n",
    "    model.append(knn_bow_ds)\n",
    "    accuracy.append(acc)\n",
    "    f1_score.append(f1)\n",
    "    \n",
    "    print(\"Done: \", i)\n",
    "#print(\"Validation Accuracy: \", acc)\n",
    "#print(\"\\nPrecision: \", precision)\n",
    "#print(\"Average Precision: \", np.mean(precision))\n",
    "#print(\"\\nRecall: \", recall)\n",
    "#print(\"Average nRecall: \", np.mean(recall))\n",
    "#print(\"\\nF1-Score: \", f1)\n",
    "#print(\"Average F1-Score: \", np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, a, f, in list(zip(index, accuracy, f1_score)):\n",
    "    print(\"Neighbors: {}, accuracy: {}, f11-score: {}\".format(i, a, np.mean(f)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
