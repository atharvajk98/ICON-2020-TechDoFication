{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import process_time\n",
    "from joblib import dump\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from data_preprocessing import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>प्रा . प्रताप हरिदास : होय , मला वाटते की हा ए...</td>\n",
       "      <td>com_tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>तर , विशिष्ट गोष्टींद्वारे , ठराविक कायद्यांद्...</td>\n",
       "      <td>bioche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>- - - - - - - - - - - - - - - - - - - - - - - ...</td>\n",
       "      <td>cse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>तर , आपला अर्धा चिन्ह 9 वाजता असेल .</td>\n",
       "      <td>phy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>म्हणून , मी असे म्हणालो की जर शेकडो , हजारो कि...</td>\n",
       "      <td>phy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41992</th>\n",
       "      <td>जरी आपण डेटा कूटबद्ध केला , तरीही हा मुख्य व्य...</td>\n",
       "      <td>cse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41993</th>\n",
       "      <td>ते म्हणतात - \" ज्याला पाहण्यासाठी डोळे , ऎकण्य...</td>\n",
       "      <td>com_tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41994</th>\n",
       "      <td>प्रथम क्रोनोलॉजिकल , क्रॉनोलॉजी म्हणजे आपल्याल...</td>\n",
       "      <td>com_tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>त्या थोड्या तपशीलावर येईल , जेणेकरून संपूर्ण ग...</td>\n",
       "      <td>bioche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>आणि एका हॉटेलमध्ये त्यांनी एका स्विस रेस्ट्राम...</td>\n",
       "      <td>com_tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41997 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     label\n",
       "0      प्रा . प्रताप हरिदास : होय , मला वाटते की हा ए...  com_tech\n",
       "1      तर , विशिष्ट गोष्टींद्वारे , ठराविक कायद्यांद्...    bioche\n",
       "2      - - - - - - - - - - - - - - - - - - - - - - - ...       cse\n",
       "3                   तर , आपला अर्धा चिन्ह 9 वाजता असेल .       phy\n",
       "4      म्हणून , मी असे म्हणालो की जर शेकडो , हजारो कि...       phy\n",
       "...                                                  ...       ...\n",
       "41992  जरी आपण डेटा कूटबद्ध केला , तरीही हा मुख्य व्य...       cse\n",
       "41993  ते म्हणतात - \" ज्याला पाहण्यासाठी डोळे , ऎकण्य...  com_tech\n",
       "41994  प्रथम क्रोनोलॉजिकल , क्रॉनोलॉजी म्हणजे आपल्याल...  com_tech\n",
       "41995  त्या थोड्या तपशीलावर येईल , जेणेकरून संपूर्ण ग...    bioche\n",
       "41996  आणि एका हॉटेलमध्ये त्यांनी एका स्विस रेस्ट्राम...  com_tech\n",
       "\n",
       "[41997 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_path = \"../dataset/original-dataset/marathi-training-data.csv\"\n",
    "training_data = read_data(training_path)\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 ची ओळ .</td>\n",
       "      <td>cse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>तर , ही एक टॉवर आहे जी टॉवरवर निश्चित केली जात...</td>\n",
       "      <td>phy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>तर , थ्रेडच्या परतीच्या स्थितीस पास करण्यासाठी...</td>\n",
       "      <td>cse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>आपण लोक शोधत आहात जे आपल्यासाठी काहीतरी करू शक...</td>\n",
       "      <td>com_tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>लिनक्स कर्नल अनुसूचीतकरणामध्ये अशी तंत्र असण्य...</td>\n",
       "      <td>cse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3775</th>\n",
       "      <td>नंतर वृद्धत्व , व्हॉट मोठ्या प्रमाणात फ्रॉन 12...</td>\n",
       "      <td>bioche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3776</th>\n",
       "      <td>आणि मग सुद्धा आपल्याला काही सेकंदांनंतर माहित ...</td>\n",
       "      <td>phy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3777</th>\n",
       "      <td>तर , आपण ELF शीर्षलेखासह प्रारंभ करू .</td>\n",
       "      <td>cse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3778</th>\n",
       "      <td>तर , त्या क्रॉस्टची जाडी आहे .</td>\n",
       "      <td>phy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779</th>\n",
       "      <td>तर , मला वाटते की ही माहिती अशी आहे की आपण एका...</td>\n",
       "      <td>phy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3780 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text     label\n",
       "0                                             1 ची ओळ .       cse\n",
       "1     तर , ही एक टॉवर आहे जी टॉवरवर निश्चित केली जात...       phy\n",
       "2     तर , थ्रेडच्या परतीच्या स्थितीस पास करण्यासाठी...       cse\n",
       "3     आपण लोक शोधत आहात जे आपल्यासाठी काहीतरी करू शक...  com_tech\n",
       "4     लिनक्स कर्नल अनुसूचीतकरणामध्ये अशी तंत्र असण्य...       cse\n",
       "...                                                 ...       ...\n",
       "3775  नंतर वृद्धत्व , व्हॉट मोठ्या प्रमाणात फ्रॉन 12...    bioche\n",
       "3776  आणि मग सुद्धा आपल्याला काही सेकंदांनंतर माहित ...       phy\n",
       "3777             तर , आपण ELF शीर्षलेखासह प्रारंभ करू .       cse\n",
       "3778                     तर , त्या क्रॉस्टची जाडी आहे .       phy\n",
       "3779  तर , मला वाटते की ही माहिती अशी आहे की आपण एका...       phy\n",
       "\n",
       "[3780 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_path = \"../dataset/original-dataset/marathi-validation-data.csv\"\n",
    "val_data = read_data(val_path)\n",
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41997\n",
      "41997\n",
      "3780\n",
      "3780\n"
     ]
    }
   ],
   "source": [
    "x_train = training_data.text.apply(lambda x: preprocess_data(x)).values.tolist()\n",
    "y_train = training_data.label.values.tolist()\n",
    "x_val = val_data.text.apply(lambda x: preprocess_data(x)).values.tolist()\n",
    "y_val = val_data.label.values.tolist()\n",
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "print(len(x_val))\n",
    "print(len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_val = label_encoder(y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41997, 1)\n",
      "(3780, 1)\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.reshape(y_train.shape[0], -1)\n",
    "y_val = y_val.reshape(y_val.shape[0], -1)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_len=50\n",
    "padding_type='post'\n",
    "truncating_type='post'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, x_train_padded, x_val_padded = tokenizer_and_pad_training(x_train, \n",
    "                                                                     x_val, \n",
    "                                                                     pad_len, \n",
    "                                                                     padding_type, \n",
    "                                                                     truncating_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(tokenizer, \"../tokenizers/DL-tokenizer-100.pk1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41997, 50)\n",
      "(3780, 50)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_padded.shape)\n",
    "print(x_val_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29198\n",
      "Total time taken:  7.752140834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(51791, 300)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = process_time()\n",
    "embedding_path1 = \"/home/eastwind/word-embeddings/fasttext/indicnlp.ft.mr.300.vec\"\n",
    "embedding_matrix1 = get_embedding_matrix(embedding_path1, vocab)\n",
    "end = process_time()\n",
    "print(\"Total time taken: \", end-start)\n",
    "embedding_matrix1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vocab:  51791\n",
      "Embedding dimensions:  300\n",
      "Input sentence dimensions:  50\n"
     ]
    }
   ],
   "source": [
    "input_dim = embedding_matrix1.shape[0]\n",
    "embedding_dim = 300\n",
    "input_len = pad_len\n",
    "print(\"Input vocab: \", input_dim)\n",
    "print(\"Embedding dimensions: \", embedding_dim)\n",
    "print(\"Input sentence dimensions: \", input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "myCB = myCallbacks(metrics='acc', threshold=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed-Forward Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 300)          15537300  \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                19264     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 15,558,776\n",
      "Trainable params: 21,476\n",
      "Non-trainable params: 15,537,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "myDNN = create_model_DNN(input_dim, \n",
    "                         embedding_dim, \n",
    "                         embedding_matrix1, \n",
    "                         input_len, \n",
    "                         trainable=False, \n",
    "                         n1=64, n2=32, \n",
    "                         kr=l2(0.015))\n",
    "myDNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-72915e0f3da3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmyDNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m embedding_layer = myDNN.add(\n\u001b[0;32m----> 3\u001b[0;31m     Embedding(input_dim=input_dim, output_dim=embedding_dim, weights=[embedding_matrix], input_length=pad_len,\n\u001b[0m\u001b[1;32m      4\u001b[0m               trainable=trainable))\n\u001b[1;32m      5\u001b[0m \u001b[0mmyDNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGlobalMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "myDNN = Sequential()\n",
    "embedding_layer = myDNN.add(\n",
    "    Embedding(input_dim=input_dim, output_dim=embedding_dim, weights=[embedding_matrix1], input_length=pad_len,\n",
    "              trainable=trainable))\n",
    "myDNN.add(GlobalMaxPooling1D())\n",
    "myDNN.add(Dense(n1, kernel_regularizer=kr, bias_regularizer=br, activation='relu'))\n",
    "myDNN.add(Dense(n2, kernel_regularizer=kr, bias_regularizer=br, activation='relu'))\n",
    "myDNN.add(Dense(4, activation='softmax'))\n",
    "myDNN.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=['acc'])\n",
    "myDNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1313/1313 [==============================] - 19s 14ms/step - loss: 1.2284 - acc: 0.6293 - val_loss: 0.9797 - val_acc: 0.6810\n",
      "Epoch 2/40\n",
      "1313/1313 [==============================] - 19s 15ms/step - loss: 0.9559 - acc: 0.6928 - val_loss: 0.9591 - val_acc: 0.6812\n",
      "Epoch 3/40\n",
      "1313/1313 [==============================] - 20s 16ms/step - loss: 0.9202 - acc: 0.7010 - val_loss: 0.9472 - val_acc: 0.6704\n",
      "Epoch 4/40\n",
      "1313/1313 [==============================] - 11s 8ms/step - loss: 0.8968 - acc: 0.7046 - val_loss: 0.8958 - val_acc: 0.7135\n",
      "Epoch 5/40\n",
      "1313/1313 [==============================] - 12s 9ms/step - loss: 0.8836 - acc: 0.7067 - val_loss: 0.8630 - val_acc: 0.7132\n",
      "Epoch 6/40\n",
      "1313/1313 [==============================] - 12s 9ms/step - loss: 0.8669 - acc: 0.7096 - val_loss: 0.8429 - val_acc: 0.7257\n",
      "Epoch 7/40\n",
      "1313/1313 [==============================] - 12s 9ms/step - loss: 0.8563 - acc: 0.7119 - val_loss: 0.8729 - val_acc: 0.7029\n",
      "Epoch 8/40\n",
      "1313/1313 [==============================] - 12s 9ms/step - loss: 0.8507 - acc: 0.7108 - val_loss: 0.8193 - val_acc: 0.7302\n",
      "Epoch 9/40\n",
      "1313/1313 [==============================] - 12s 9ms/step - loss: 0.8360 - acc: 0.7167 - val_loss: 0.8324 - val_acc: 0.7230\n",
      "Epoch 10/40\n",
      "1313/1313 [==============================] - 11s 9ms/step - loss: 0.8316 - acc: 0.7154 - val_loss: 0.8682 - val_acc: 0.7042\n",
      "Epoch 11/40\n",
      "1313/1313 [==============================] - 12s 9ms/step - loss: 0.8261 - acc: 0.7169 - val_loss: 0.8196 - val_acc: 0.7201\n",
      "Epoch 12/40\n",
      "1313/1313 [==============================] - 17s 13ms/step - loss: 0.8208 - acc: 0.7174 - val_loss: 0.8052 - val_acc: 0.7294\n",
      "Epoch 13/40\n",
      "1313/1313 [==============================] - 12s 9ms/step - loss: 0.8195 - acc: 0.7178 - val_loss: 0.8445 - val_acc: 0.7029\n",
      "Epoch 14/40\n",
      "1313/1313 [==============================] - 12s 10ms/step - loss: 0.8137 - acc: 0.7206 - val_loss: 0.8090 - val_acc: 0.7259\n",
      "Epoch 15/40\n",
      " 946/1313 [====================>.........] - ETA: 3s - loss: 0.8109 - acc: 0.7207"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2f685663a342>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history1 = myDNN.fit(x_train_padded, \n\u001b[0m\u001b[1;32m      2\u001b[0m                      \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                      \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                      \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                      \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history1 = myDNN.fit(x_train_padded, \n",
    "                     y_train, \n",
    "                     epochs=40, \n",
    "                     batch_size=32, \n",
    "                     verbose=1, \n",
    "                     validation_data = (x_val_padded, y_val), \n",
    "                     callbacks=[myCB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curves(history1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"FFNN/FFNN-n1.64-n2.32-kr0015-vacc8585\"\n",
    "myDNN.save(\"../models/\"+name+\".h5\")\n",
    "# serialize model to JSON\n",
    "model_json = myDNN.to_json()\n",
    "with open(\"../models/\"+name+\".json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "myDNN.save_weights(\"../models/\"+name+\"_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDNN = model_load(\"../models/FFNN/FFNN-n1.64-n2.32-kr0015-vacc8585.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = np.argmax(myDNN.predict(x_val_padded), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, precision, recall, f1 = classification_report(y_val, results1)\n",
    "print(\"Validation Accuracy: \", acc)\n",
    "print(\"\\nPrecision: \", precision)\n",
    "print(\"Average Precision: \", np.mean(precision))\n",
    "print(\"\\nRecall: \", recall)\n",
    "print(\"Average nRecall: \", np.mean(recall))\n",
    "print(\"\\nF1-Score: \", f1)\n",
    "print(\"Average F1-Score: \", np.mean(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 300)          15537300  \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 96, 64)            96064     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 15,633,624\n",
      "Trainable params: 96,324\n",
      "Non-trainable params: 15,537,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "myCNN = create_model_CNN(input_dim, \n",
    "                         embedding_dim, \n",
    "                         embedding_matrix1, input_len, \n",
    "                         trainable=False, \n",
    "                         n1=64, k=5, \n",
    "                         d=0.25, kr=l2(0.02))\n",
    "myCNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "657/657 [==============================] - 47s 71ms/step - loss: 1.0700 - acc: 0.7174 - val_loss: 0.8205 - val_acc: 0.7661\n",
      "Epoch 2/40\n",
      "657/657 [==============================] - 55s 83ms/step - loss: 0.8570 - acc: 0.7537 - val_loss: 0.8124 - val_acc: 0.7653\n",
      "Epoch 3/40\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 0.8484 - acc: 0.7599 - val_loss: 0.8264 - val_acc: 0.7577\n",
      "Epoch 4/40\n",
      "657/657 [==============================] - 54s 82ms/step - loss: 0.8421 - acc: 0.7628 - val_loss: 0.8077 - val_acc: 0.7799\n",
      "Epoch 5/40\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.8375 - acc: 0.7665 - val_loss: 0.8010 - val_acc: 0.7720\n",
      "Epoch 6/40\n",
      "657/657 [==============================] - 52s 79ms/step - loss: 0.8379 - acc: 0.7648 - val_loss: 0.7986 - val_acc: 0.7844\n",
      "Epoch 7/40\n",
      "657/657 [==============================] - 60s 92ms/step - loss: 0.8310 - acc: 0.7687 - val_loss: 0.8056 - val_acc: 0.7775\n",
      "Epoch 8/40\n",
      "657/657 [==============================] - 54s 82ms/step - loss: 0.8281 - acc: 0.7729 - val_loss: 0.7991 - val_acc: 0.7780\n",
      "Epoch 9/40\n",
      "657/657 [==============================] - 55s 83ms/step - loss: 0.8333 - acc: 0.7710 - val_loss: 0.8056 - val_acc: 0.7730\n",
      "Epoch 10/40\n",
      "332/657 [==============>...............] - ETA: 27s - loss: 0.8350 - acc: 0.7710"
     ]
    }
   ],
   "source": [
    "history2 = myCNN.fit(x_train_padded, \n",
    "                     y_train, \n",
    "                     epochs=40, \n",
    "                     batch_size=64, \n",
    "                     verbose=1, \n",
    "                     validation_data = (x_val_padded, y_val), \n",
    "                     callbacks=[myCB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curves(history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name =\"CNN/CNN-n1.64n2.64-kr0015-vacc8632\"\n",
    "myCNN.save(\"../models/\"+name+\".h5\")\n",
    "# serialize model to JSON\n",
    "model_json = myCNN.to_json()\n",
    "with open(\"../models/\"+name+\".json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "myCNN.save_weights(\"../models/\"+name+\"_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myCNN = model_load(\"../models/CNN/CNN-n1.64n2.64-kr0015-vacc8632.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = np.argmax(myCNN.predict(x_val_padded), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, precision, recall, f1 = classification_report(y_val, results2)\n",
    "print(\"Validation Accuracy: \", acc)\n",
    "print(\"\\nPrecision: \", precision)\n",
    "print(\"Average Precision: \", np.mean(precision))\n",
    "print(\"\\nRecall: \", recall)\n",
    "print(\"Average nRecall: \", np.mean(recall))\n",
    "print(\"\\nF1-Score: \", f1)\n",
    "print(\"Average F1-Score: \", np.mean(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myLSTM = create_model_LSTM(input_dim, \n",
    "                           embedding_dim, \n",
    "                           embedding_matrix1, \n",
    "                           input_len, \n",
    "                           trainable=True, \n",
    "                           n1=32, n2=32, \n",
    "                           d=0.3)\n",
    "myLSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history3 = myLSTM.fit(x_train_padded, \n",
    "                      y_train, \n",
    "                      epochs=40, \n",
    "                      batch_size=64, \n",
    "                      verbose=1, \n",
    "                      validation_data = (x_val_padded, y_val), \n",
    "                      callbacks=[myCB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curves(history3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name= \"LSTM/Bi-LST-n1.64-n2.64-kr0015-vacc868\"\n",
    "myLSTM.save(\"../models/\"+name+\".h5\")\n",
    "# serialize model to JSON\n",
    "model_json = myLSTM.to_json()\n",
    "with open(\"../models/\"+name+\".json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "myLSTM.save_weights(\"../models/\"+name+\"_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myLSTM = model_load(\"../models/LSTM/Bi-LST-n1.64-n2.64-kr0015-vacc868.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results3 = np.argmax(myLSTM.predict(x_val_padded), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, precision, recall, f1 = classification_report(y_val, results3)\n",
    "print(\"Validation Accuracy: \", acc)\n",
    "print(\"\\nPrecision: \", precision)\n",
    "print(\"Average Precision: \", np.mean(precision))\n",
    "print(\"\\nRecall: \", recall)\n",
    "print(\"Average nRecall: \", np.mean(recall))\n",
    "print(\"\\nF1-Score: \", f1)\n",
    "print(\"Average F1-Score: \", np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
