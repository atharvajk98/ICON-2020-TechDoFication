{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext.util\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextToTensor:\n",
    "\n",
    "    # --------------------------------------- Constructor --------------------------------------- \n",
    "    \n",
    "    def __init__(self, tokenizer, max_len):\n",
    "    \n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    \n",
    "    def string_to_tensor(self, string_list: list) -> list:\n",
    "        \"\"\"\n",
    "        A method to convert a string list to a tensor for a deep learning model\n",
    "        \"\"\"    \n",
    "        string_list = self.tokenizer.texts_to_sequences(string_list)\n",
    "        string_list = pad_sequences(string_list, maxlen=self.max_len)\n",
    "        \n",
    "        return string_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings:\n",
    "\n",
    "    \"\"\"\n",
    "    A class to read the word embedding file and to create the word embedding matrix\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path, vector_dimension):\n",
    "        self.path = path \n",
    "        self.vector_dimension = vector_dimension\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_coefs(word, *arr): \n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "    \n",
    "    def get_embedding_index(self):\n",
    "        embeddings_index = dict(self.get_coefs(*o.split(\" \")) for o in open(self.path, errors='ignore'))\n",
    "        return embeddings_index\n",
    "\n",
    "    \n",
    "    def create_embedding_matrix(self, tokenizer, max_features):\n",
    "        \"\"\"\n",
    "        A method to create the embedding matrix\n",
    "        \"\"\"\n",
    "        model_embed = self.get_embedding_index()\n",
    "\n",
    "        embedding_matrix = np.zeros((max_features + 1, self.vector_dimension))\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index > max_features:\n",
    "                break\n",
    "            else:\n",
    "                try:\n",
    "                    embedding_matrix[index] = model_embed[word]\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        return embedding_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models._fasttext_bin import load\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "marathi_embeddings = KeyedVectors.load_word2vec_format('C:/Users/Amey/Desktop/Neural Networks/Data/Technodification/cc.mr.300.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0233  0.056  -0.0185  0.0396 -0.011  -0.0608 -0.0087 -0.0886  0.0124\n",
      " -0.1066  0.0031 -0.0524 -0.0261 -0.0324  0.0053 -0.0085 -0.0133  0.0498\n",
      " -0.0614 -0.038   0.0037 -0.0232  0.0522  0.0014 -0.0146 -0.0235 -0.0196\n",
      "  0.0005  0.0147 -0.0096 -0.0016 -0.0201  0.0071 -0.0342 -0.0091 -0.0208\n",
      "  0.0331 -0.0564  0.03    0.0187  0.0193  0.0166 -0.0147 -0.0158 -0.0191\n",
      " -0.0029 -0.0837 -0.0334 -0.0188 -0.038  -0.0305  0.0477  0.039   0.0205\n",
      "  0.0142  0.0436  0.0141 -0.041  -0.0942 -0.0151  0.0113  0.0272  0.0329\n",
      " -0.0221 -0.0119  0.0388 -0.0322 -0.0247  0.0071 -0.0251 -0.0068 -0.0084\n",
      " -0.0114 -0.0186 -0.0155 -0.0262  0.0136  0.0299  0.0745  0.005  -0.0231\n",
      "  0.0093 -0.0141  0.0232 -0.1405 -0.0382 -0.05   -0.0241  0.0039  0.0321\n",
      " -0.0181  0.0463 -0.0487  0.2364 -0.0334 -0.0109  0.0289  0.058   0.0045\n",
      "  0.0208  0.1884 -0.024  -0.0055 -0.1083  0.03   -0.0382 -0.0833  0.0132\n",
      "  0.0075 -0.0228 -0.1422 -0.0304  0.0473 -0.004  -0.038   0.0031 -0.0714\n",
      "  0.0186  0.0519 -0.022   0.0064 -0.0477 -0.0088 -0.0866 -0.0221 -0.0228\n",
      "  0.03   -0.0117 -0.0131  0.0097 -0.011  -0.004  -0.0009  0.0008 -0.0086\n",
      "  0.0561  0.1001 -0.0074  0.0127 -0.0345  0.0037 -0.0387  0.008   0.0108\n",
      " -0.0432 -0.0079 -0.0571  0.0207  0.0388 -0.0243  0.0724 -0.0532  0.0105\n",
      " -0.0062 -0.0161  0.0197 -0.0459 -0.024   0.0274  0.0025 -0.0016 -0.0151\n",
      "  0.0641 -0.0189 -0.0174  0.0226  0.0737 -0.0272  0.048   0.0224  0.028\n",
      " -0.0096  0.0094 -0.0065  0.0227 -0.0248  0.0097 -0.017   0.0307 -0.0219\n",
      "  0.0029  0.024   0.0003 -0.0144  0.075   0.0453 -0.0352  0.0327 -0.0237\n",
      "  0.0259 -0.0487 -0.0348  0.0568 -0.0327  0.1256 -0.0085  0.0358  0.0246\n",
      "  0.0179  0.041   0.2562 -0.0069 -0.0081 -0.0124 -0.0661  0.0581 -0.0183\n",
      "  0.0076 -0.0469 -0.0418  0.012  -0.07    0.0273  0.0099  0.0651  0.0137\n",
      "  0.0316 -0.0131  0.0134 -0.041   0.0154 -0.0364  0.0114 -0.0117  0.0391\n",
      "  0.016   0.0205  0.0146 -0.205  -0.0648 -0.0264 -0.0703  0.0184  0.017\n",
      " -0.0104 -0.0244 -0.0114 -0.0376 -0.0165 -0.0111  0.0024 -0.0376  0.0064\n",
      " -0.0507  0.0159 -0.0327 -0.0396  0.0509 -0.0144 -0.0558  0.0521 -0.0618\n",
      "  0.0246  0.0281  0.0109 -0.0387  0.0223 -0.0003  0.0221 -0.0129 -0.0519\n",
      " -0.0085 -0.008  -0.029  -0.0298 -0.0107  0.0062 -0.0314 -0.0095  0.0224\n",
      " -0.0221  0.0227 -0.047   0.0149  0.0375  0.0181 -0.0257 -0.0334 -0.0652\n",
      "  0.0325 -0.0331 -0.0169  0.0299 -0.016   0.0238 -0.0055  0.0058 -0.0496\n",
      " -0.0146  0.0357  0.0588  0.0197 -0.0629 -0.0412  0.0182 -0.0435  0.0111\n",
      "  0.0086 -0.0074 -0.0613]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amey\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print((marathi_embeddings.wv['आहे']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
