{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 145,
>>>>>>> 21391f808025db0af42514734c728739fd057ddc
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess:\n",
    "        \n",
    "        # --------------------------------------- Constructor --------------------------------------- \n",
    "        \n",
    "        def __init__(self,stopword_list):\n",
    "            self.data_path = ''\n",
    "            self.stopword_list = stopword_list\n",
    "                \n",
    "\n",
    "        # --------------------------------------- Expand Concatenations --------------------------------------- \n",
    "        \n",
    "        def expand_concatenations(self, word):\n",
    "            \n",
    "            \n",
    "            if not re.match('[a-zA-Z]+', word) or re.match('/d+',word):\n",
    "                for i in range(len(word)):\n",
    "                    if not('DEVANAGARI ' in unicodedata.name(word[i])):\n",
    "                        word = word[:i] if( len(word[i:]) < 2 and not word[i:].isnumeric()) else word[:i] + \" \" + word[i:]\n",
    "                        break\n",
    "            else:\n",
    "                for i in range(len(word)):\n",
    "                    if ('DEVANAGARI ' in unicodedata.name(word[i])):\n",
    "                        word = word[i:] if( len(word[:i]) < 2 and not word[:i].isnumeric() ) else word[:i] + \" \" + word[i:]\n",
    "                        break\n",
    "\n",
    "            return(word)\n",
    "    \n",
    "    \n",
    "        # --------------------------------------- Preprocess --------------------------------------- \n",
    "\n",
    "        def clean_text(self,text: str) -> str:\n",
    "            try:\n",
    "                special_chars = r'''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "                stemmer = PorterStemmer()\n",
    "                lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "                if not(isinstance(text, str)): text = str(text)\n",
    "\n",
    "                #Removing unprintable characters\n",
    "                text = ''.join(x for x in text if x.isprintable())\n",
    "\n",
    "                # Cleaning the urls\n",
    "                text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "\n",
    "                # Cleaning the html elements\n",
    "                text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "                # Removing the punctuations\n",
    "                text = re.sub('[!#?,.:\";-@#$%^&*_~<>()-]', '', text)\n",
    "\n",
    "\n",
    "                # Removing stop words\n",
    "                text = ' '.join([word for word in text.split() if word not in self.stopword_list])\n",
    "\n",
    "                # Expanding noisy concatenations (Eg: algorithmआणि  -> algorithm आणि ) \n",
    "                text = ' '.join([self.expand_concatenations(word) for word in text.split()])\n",
    "\n",
    "                preprocessed_text = \"\"\n",
    "\n",
    "                for word in text.split(): \n",
    "                    if (re.match('\\d+', word)):\n",
    "                        if(word.isnumeric()):\n",
    "                            preprocessed_text = preprocessed_text + '#N' + \" \"\n",
    "                        else:\n",
    "                            preprocessed_text = preprocessed_text + word.lower() + \" \"\n",
    "\n",
    "                    else:\n",
    "                        if(re.match('[a-zA-Z]+', word)):\n",
    "                            if not len(word) < 2:\n",
    "                                word = word.lower()\n",
    "    #                             word = lemmatizer.lemmatize(word, pos='v')\n",
    "                                preprocessed_text = preprocessed_text + word + \" \"\n",
    "\n",
    "                        else:\n",
    "                            preprocessed_text = preprocessed_text + word + \" \"\n",
    "\n",
    "                return preprocessed_text\n",
    "            \n",
    "            except ValueError as ve:\n",
    "                print('Error processing:\\t',text)\n",
<<<<<<< HEAD
    "                return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = Preprocess([])"
=======
    "                return ''\n",
    "        "
>>>>>>> 21391f808025db0af42514734c728739fd057ddc
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 149,
>>>>>>> 21391f808025db0af42514734c728739fd057ddc
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "त्यांना CO2 2H20 सीओ२ लागेल99 , Animalत्यांना त्यांनाAnimal Analogy_त्यांना Science२१ १२Number \t--->\t त्यांना co2 2h20 सीओ२ लागेल #N animal त्यांना त्यांना animal analogy त्यांना science #N #N number  \n",
      "\n",
<<<<<<< HEAD
      "Final result: \n",
      " त्यांना co2 सीओ२ co #N लागेल #N animal त्यांना त्यांना animal analogy त्यांना science #N #N number\n",
      "\n",
      "Final result: \n",
      " his am atharva #N kulkarni #N #N सी\n"
=======
      "!@)$&%!#)&$!&$!$I am Atharva ११.२२ Kulkarni 11.22 a B 1 सी \t--->\t am atharva #N kulkarni #N #N सी  \n",
      "\n"
>>>>>>> 21391f808025db0af42514734c728739fd057ddc
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "#sampletext1 = df['text'].sample().values\n",
    "sampletext2 = 'त्यांना जनतेला पटवून द्यावे लागेल99 '\n",
    "\n",
    "test_list = ['त्यांना CO2 सीओ२ co२ लागेल99 , Animalत्यांना त्यांनाAnimal Analogy_त्यांना Science२१ १२Number',\n",
    "             '!@)$&%!#)&$!&$!$His am Atharva ११.२२ Kulkarni 11.22 a B 1 सी']\n",
    "             \n",
    "for text in test_list:\n",
    "    result = pp.clean_text(text)\n",
    "    print(\"\\nFinal result: \\n\", result)"
=======
    "if __name__ == '__main__':\n",
    "    \n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('../Technodifacation/Data/training_data_marathi.csv')\n",
    "    \n",
    "    sampletext1 = df['text'].sample().values\n",
    "    pp = Preprocess([])\n",
    "    sampletext2 = 'त्यांना जनतेला पटवून द्यावे लागेल99 '\n",
    "\n",
    "    test_list1 = ['त्यांना','H20', '2H20','Animal2Animal' ,'सी२ओ२', 'लागेल99', 'Animalत्यांना',\n",
    "                 'त्यांनाAnimal', 'Analogy_त्यांना', 'Science२१', '१२Number', '!@)$&%!#)&$!&$!$B Bo ', '११.२२','I', '१','1','11.22','a','B','सी']\n",
    "\n",
    "    test_list2 = ['त्यांना CO2 2H20 सीओ२ लागेल99 , Animalत्यांना त्यांनाAnimal Analogy_त्यांना Science२१ १२Number',\n",
    "                 '!@)$&%!#)&$!&$!$I am Atharva ११.२२ Kulkarni 11.22 a B 1 सी']\n",
    "\n",
    "    for text in test_list2:\n",
    "        print(text, '\\t--->\\t', pp.clean_text(text),'\\n')   "
>>>>>>> 21391f808025db0af42514734c728739fd057ddc
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../dataset/original-dataset/marathi-training-data.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data.text.apply(lambda x: pp.clean_text(x))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data.text.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
